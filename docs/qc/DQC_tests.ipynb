{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c9a390",
   "metadata": {},
   "source": [
    "# Initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4129d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dqc\n",
    "import dqc.xc\n",
    "import dqc.utils\n",
    "\n",
    "from DQCAdapter import DQCAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5195e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLDAX(dqc.xc.CustomXC):\n",
    "    def __init__(self, a, p):\n",
    "        super().__init__()\n",
    "        self.a = a\n",
    "        self.p = p\n",
    "\n",
    "    @property\n",
    "    def family(self):\n",
    "        # 1 for LDA, 2 for GGA, 4 for MGGA\n",
    "        return 1\n",
    "\n",
    "    # NB: it is not \\epsilon, it is \\epsilon * \\rho! \n",
    "    # It can be seen in 292-294 of dqc/hamiltonian/hcgto.py\n",
    "    # It means, that V_{XC} = dget_edensityxc/drho without second term.\n",
    "    def get_edensityxc(self, densinfo):\n",
    "        # densinfo has up and down components\n",
    "        if isinstance(densinfo, dqc.utils.SpinParam):\n",
    "            # spin-scaling of the exchange energy\n",
    "            return 0.5 * (self.get_edensityxc(densinfo.u * 2) + self.get_edensityxc(densinfo.d * 2))\n",
    "        else:\n",
    "            rho = densinfo.value.abs() + 1e-15  # safeguarding from nan\n",
    "            return self.a * rho ** self.p\n",
    "    \n",
    "    # it is for tests\n",
    "    def get_vxc_analytical(self, densinfo):\n",
    "        if isinstance(densinfo, dqc.utils.SpinParam):\n",
    "            # spin-scaling of the exchange energy\n",
    "            return 0.5 * (self.get_vxc_analytical(densinfo.u * 2) + self.get_vxc_analytical(densinfo.d * 2))\n",
    "        else:\n",
    "            rho = densinfo.value.abs() + 1e-15  # safeguarding from nan\n",
    "            return (self.a * self.p * rho ** (self.p - 1))\n",
    "        \n",
    "    def get_edensityxc_derivative(self, densinfo, number_of_parameter):\n",
    "        # densinfo has up and down components\n",
    "        if isinstance(densinfo, dqc.utils.SpinParam):\n",
    "            # spin-scaling of the exchange energy\n",
    "            return 0.5 * (self.get_edensityxc_derivative(densinfo.u * 2, number_of_parameter) \n",
    "                          + self.get_edensityxc_derivative(densinfo.d * 2, number_of_parameter))\n",
    "        else:\n",
    "            rho = densinfo.value.abs() + 1e-15  # safeguarding from nan\n",
    "            if number_of_parameter == 0: # parameter a\n",
    "                return rho ** self.p\n",
    "            elif number_of_parameter == 1: # parameter p\n",
    "                # TODO: it is incorrect derivative\n",
    "                return self.a * rho ** (self.p - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f0f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.Parameter(torch.tensor(1.0, dtype=torch.double))\n",
    "p = torch.nn.Parameter(torch.tensor(2.0, dtype=torch.double))\n",
    "myxc = MyLDAX(a, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2745cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-54.0932, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radium/miniconda3/lib/python3.9/site-packages/xitorch/_impls/optimize/root/rootsolver.py:163: ConvergenceWarning: The rootfinder does not converge after 50 iterations. Best |dx|=2.508e-02, |f|=2.288e-01 at iter 32\n",
      "  warnings.warn(ConvergenceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "mol = dqc.Mol(moldesc=\"N -1 0 0; N 1 0 0\", basis=\"3-21G\")\n",
    "qc = dqc.KS(mol, xc=myxc).run()\n",
    "ene = qc.energy()\n",
    "print(ene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a2aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = DQCAdapter(qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b7b669",
   "metadata": {},
   "source": [
    "# Check orthonormality of basis set in DQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de80873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_all_orbitals = adapter.get_number_of_all_orbitals()\n",
    "overlap = adapter.get_overlap_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14916955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3030e-14, dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.matrix_norm(overlap - torch.eye(number_of_all_orbitals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e911474d",
   "metadata": {},
   "source": [
    "# Check density matrix vs orbital coefficients consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "847da632",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = adapter.get_density_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e495e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = adapter.get_orbital_coefficients()\n",
    "coefficients.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5de652",
   "metadata": {},
   "source": [
    "They must have the same norm (it can differs in two times because of $f_a=2$ in the case of RKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65915ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6458, dtype=torch.float64, grad_fn=<CopyBackwards>)\n",
      "tensor(5.2915, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(torch.linalg.matrix_norm(torch.matmul(coefficients, coefficients.t())))\n",
    "print(torch.linalg.matrix_norm(dm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3209d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2924, dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: other checks?\n",
    "# TODO: strange value of \n",
    "print(torch.linalg.matrix_norm(dm - torch.matmul(coefficients, coefficients.t())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9081ad",
   "metadata": {},
   "source": [
    "# Check symmetry of electron-electron repulsion tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee9b705",
   "metadata": {},
   "source": [
    "$$G_{ijkl} = \\iint b_i(\\vec{r}) \\frac{b_k(\\vec{r'})b_l(\\vec{r'})}{|\\vec{r}-\\vec{r'}|} b_j(\\vec{r})d\\vec{r'}d\\vec{r}$$\n",
    "It must have symmetry of i<->j and k<->l permutations, let's check it. We are going to calculate something like norm of remainder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2debc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "electronic_repulsion_tensor = adapter.get_four_center_elrep_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68557f52",
   "metadata": {},
   "source": [
    "i<->j and k<->l should be almost zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15267504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2990e-13, dtype=torch.float64)\n",
      "tensor(7.9542e-15, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(torch.linalg.matrix_norm(torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(0, 1))))\n",
    "print(torch.linalg.matrix_norm(torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(2, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db11a04",
   "metadata": {},
   "source": [
    "i<->k, i<->l, j<->k and j<->l should not be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c8bd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.9926, dtype=torch.float64)\n",
      "tensor(13.9926, dtype=torch.float64)\n",
      "tensor(13.9926, dtype=torch.float64)\n",
      "tensor(13.9926, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(torch.linalg.matrix_norm(torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(0, 2))))\n",
    "print(torch.linalg.matrix_norm(torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(0, 3))))\n",
    "print(torch.linalg.matrix_norm(torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(1, 2))))\n",
    "print(torch.linalg.matrix_norm(torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(1, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fcb239",
   "metadata": {},
   "source": [
    "# Check density at grid sums to number of electrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b10188a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_at_grid = qc.get_system().get_hamiltonian()._dm2densinfo(dm)\n",
    "volumes_at_grid = qc.get_system().get_hamiltonian().grid.get_dvolume()\n",
    "number_of_electrons_integration_of_density = torch.einsum(\"i,i->\", density_at_grid.value, volumes_at_grid)\n",
    "number_of_electrons_from_occupancies = adapter.get_orbital_occupancy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be73ddc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-8.0931e-05, dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_electrons_integration_of_density - number_of_electrons_from_occupancies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de919c1b",
   "metadata": {},
   "source": [
    "# Compare analytical and autograd $V_{XC}[\\rho]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ada90c",
   "metadata": {},
   "source": [
    "Let's talk about LDA. For it:\n",
    "$$V_{XC}[\\rho](\\vec{r}) = \\epsilon_{xc}[\\rho](\\vec{r}) + \\frac{\\partial \\epsilon_{xc}[\\rho](\\vec{r})}{\\partial \\rho(\\vec{r})}$$\n",
    "\n",
    "But DQC uses autograd.grad instead of analytical expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bbbf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqc.utils.datastruct import ValGrad, SpinParam\n",
    "\n",
    "\n",
    "vxc_autograd_at_grid = qc.get_system().get_hamiltonian().xc.get_vxc(density_at_grid)\n",
    "vxc_autograd_matrix = qc.get_system().get_hamiltonian()._get_vxc_from_potinfo(vxc_autograd_at_grid)\n",
    "# eqiuvalent to: vxc_autograd_matrix = qc.get_system().get_hamiltonian().get_vxc(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "293a563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vxc_analytical_at_grid = ValGrad(qc.get_system().get_hamiltonian().xc.get_vxc_analytical(density_at_grid))\n",
    "vxc_analytical_matrix = qc.get_system().get_hamiltonian()._get_vxc_from_potinfo(vxc_analytical_at_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f772ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6382e-14, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.linalg.vector_norm(vxc_autograd_at_grid.value - vxc_analytical_at_grid.value))\n",
    "print(torch.linalg.matrix_norm(vxc_autograd_matrix.fullmatrix() - vxc_analytical_matrix.fullmatrix()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
