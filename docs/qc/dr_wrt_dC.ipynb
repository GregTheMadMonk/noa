{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d794576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dqc\n",
    "import dqc.xc\n",
    "import dqc.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c0f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLDAX(dqc.xc.CustomXC):\n",
    "    def __init__(self, a, p):\n",
    "        super().__init__()\n",
    "        self.a = a\n",
    "        self.p = p\n",
    "\n",
    "    @property\n",
    "    def family(self):\n",
    "        # 1 for LDA, 2 for GGA, 4 for MGGA\n",
    "        return 1\n",
    "\n",
    "    def get_edensityxc(self, densinfo):\n",
    "        # densinfo has up and down components\n",
    "        if isinstance(densinfo, dqc.utils.SpinParam):\n",
    "            # spin-scaling of the exchange energy\n",
    "            return 0.5 * (self.get_edensityxc(densinfo.u * 2) + self.get_edensityxc(densinfo.d * 2))\n",
    "        else:\n",
    "            rho = densinfo.value.abs() + 1e-15  # safeguarding from nan\n",
    "            return self.a * rho ** self.p\n",
    "        \n",
    "    def get_edensityxc_derivative(self, densinfo, number_of_parameter):\n",
    "        # densinfo has up and down components\n",
    "        if isinstance(densinfo, dqc.utils.SpinParam):\n",
    "            # spin-scaling of the exchange energy\n",
    "            return 0.5 * (self.get_edensityxc_derivative(densinfo.u * 2, number_of_parameter) \n",
    "                          + self.get_edensityxc_derivative(densinfo.d * 2, number_of_parameter))\n",
    "        else:\n",
    "            rho = densinfo.value.abs() + 1e-15  # safeguarding from nan\n",
    "            if number_of_parameter == 0: # parameter a\n",
    "                return rho ** self.p\n",
    "            elif number_of_parameter == 1: # parameter p\n",
    "                return self.a * rho ** (self.p - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9199361",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.Parameter(torch.tensor(1.0, dtype=torch.double))\n",
    "p = torch.nn.Parameter(torch.tensor(4.0, dtype=torch.double))\n",
    "myxc = MyLDAX(a, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37d231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3-21G basis for atomz 7 does not exist, but we will download it\n",
      "Downloaded to /home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/dqc/api/.database/3-21g/07.gaussian94\n",
      "tensor(-27.0517, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rolan/miniconda3/envs/noa/lib/python3.9/site-packages/xitorch/_impls/optimize/root/rootsolver.py:163: ConvergenceWarning: The rootfinder does not converge after 50 iterations. Best |dx|=9.882e+04, |f|=9.798e+04 at iter 50\n",
      "  warnings.warn(ConvergenceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "mol = dqc.Mol(moldesc=\"N -1 0 0; N 1 0 0\", basis=\"3-21G\")\n",
    "qc = dqc.KS(mol, xc=myxc).run()\n",
    "ene = qc.energy()\n",
    "print(ene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf6b3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36572, 18])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc._engine.hamilton.basis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee18bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = qc._dm.detach().clone() # density matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad03ae",
   "metadata": {},
   "source": [
    "Example: here the way of calculating $$\\int b_i(\\vec{r}) b_l(\\vec{r}) b_k(\\vec{r})b_j(\\vec{r})d\\vec{r}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a67921ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36572, 18])\n",
      "torch.Size([36572, 18, 18, 18])\n",
      "torch.Size([36572, 18])\n",
      "torch.Size([18, 18, 18, 18])\n"
     ]
    }
   ],
   "source": [
    "a = qc._engine.hamilton.basis\n",
    "#a = torch.tensor([[1, 2, 3]])\n",
    "print(a.size())\n",
    "b = torch.einsum(\"ri,rj,rk->rijk\", a, a, a)\n",
    "print(b.size())\n",
    "c = qc._engine.hamilton.basis_dvolume\n",
    "print(c.size())\n",
    "# d = torch.matmul(c.transpose(-2, -1), b)\n",
    "d = torch.einsum(\"rl,rijk->ijkl\", c, b)\n",
    "print(d.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136da2e",
   "metadata": {},
   "source": [
    "Here we calculating $$\\frac{\\partial V_{XC}[\\rho](\\vec{r_r};\\;\\vec{\\theta})}{\\partial \\rho(\\vec{r_r})}$$ at points $\\vec{r_r}$ of grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b2b18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqc.utils.datastruct import AtomCGTOBasis, ValGrad, SpinParam, DensityFitInfo\n",
    "\n",
    "def get_dvxc_wrt_dro_xc(xc, densinfo):\n",
    "    # densinfo.value: (*BD, nr)\n",
    "    # return:\n",
    "    # potentialinfo.value: (*BD, nr)\n",
    "    \n",
    "    # mark the densinfo components as requiring grads\n",
    "    with xc._enable_grad_densinfo(densinfo):\n",
    "        with torch.enable_grad():\n",
    "            edensity = xc.get_edensityxc(densinfo)  # (*BD, nr)\n",
    "        grad_outputs = torch.ones_like(edensity)\n",
    "        grad_enabled = torch.is_grad_enabled()\n",
    "\n",
    "        if not isinstance(densinfo, ValGrad): # polarized case\n",
    "            raise NotImplementedError(\"polarized case is not implemented\")\n",
    "        else: # unpolarized case\n",
    "            if xc.family == 1:  # LDA\n",
    "                potinfo, = torch.autograd.grad(\n",
    "                    edensity, densinfo.value, create_graph=grad_enabled,\n",
    "                    grad_outputs=grad_outputs)\n",
    "                print(\"potential info\\n\", potinfo)\n",
    "                derivative_of_potinfo_wrt_ro, = torch.autograd.grad(\n",
    "                    potinfo, densinfo.value, create_graph=grad_enabled,\n",
    "                    grad_outputs=grad_outputs)\n",
    "                return ValGrad(value=derivative_of_potinfo_wrt_ro)\n",
    "            else: # GGA and others\n",
    "                raise NotImplementedError(\"Default dvxc wrt dro for family %d is not implemented\" % self.family)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3426aa",
   "metadata": {},
   "source": [
    "And here we are want to calculate $$\\int b_i(\\vec{r}) b_l(\\vec{r}) \\frac{\\partial V_{XC}[\\rho](\\vec{r_r};\\;\\vec{\\theta})}{\\partial \\rho(\\vec{r_r})} b_k(\\vec{r})b_j(\\vec{r})d\\vec{r}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "618b4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xitorch as xt\n",
    "\n",
    "def get_dvxc_wrt_dro_from_derivative_of_potinfo_wrt_ro(hamiltonian, \n",
    "                                                       derivative_of_potinfo_wrt_ro: ValGrad) -> xt.LinearOperator:\n",
    "    # obtain the vxc operator from the potential information\n",
    "    # potinfo.value: (*BD, nr)\n",
    "    # self.basis: (nr, nao)\n",
    "    # self.grad_basis: (ndim, nr, nao)\n",
    "    \n",
    "    # prepare the fock matrix component from vxc\n",
    "    \n",
    "    # TODO: do the same stuff\n",
    "    #     nao = hamiltonian.basis.shape[-1]\n",
    "    #     mat = torch.zeros((*derivative_of_potinfo_wrt_ro.value.shape[:-1], nao, nao), dtype=hamiltonian.dtype, device=hamiltonian.device)\n",
    "    #     vb = derivative_of_potinfo_wrt_ro.value.unsqueeze(-1) * hamiltonian.basis  # (*BD, nr, nao)\n",
    "    #     mat = torch.matmul(hamiltonian.basis_dvolume.transpose(-2, -1), vb)\n",
    "\n",
    "    #     mat = hamiltonian._orthozer.convert2(mat)\n",
    "    #     mat = (mat + mat.transpose(-2, -1)) * 0.5\n",
    "    \n",
    "    mat = torch.einsum(\"r,ri,rj,rk,rl->ijkl\", \n",
    "                       derivative_of_potinfo_wrt_ro.value, \n",
    "                       hamiltonian.basis, \n",
    "                       hamiltonian.basis, \n",
    "                       hamiltonian.basis,\n",
    "                       hamiltonian.basis_dvolume)\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6680722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dvxc_wrt_dro_dm(hamiltonian, dm):\n",
    "    densinfo = SpinParam.apply_fcn(lambda dm_: hamiltonian._dm2densinfo(dm_), dm)  # value: (*BD, nr)\n",
    "    print(\"density info\\n\", densinfo)\n",
    "    derivative_of_potinfo_wrt_ro = get_dvxc_wrt_dro_xc(hamiltonian.xc, densinfo)  # value: (*BD, nr)\n",
    "    print(\"derivative of potential info wrt density\\n\", derivative_of_potinfo_wrt_ro)\n",
    "    dvxc_wrt_dro = get_dvxc_wrt_dro_from_derivative_of_potinfo_wrt_ro(hamiltonian, derivative_of_potinfo_wrt_ro)\n",
    "    return dvxc_wrt_dro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54ffe2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density info\n",
      " ValGrad(value=tensor([0.0003, 0.0003, 0.0003,  ..., 0.0000, 0.0000, 0.0000],\n",
      "       dtype=torch.float64), grad=None, lapl=None, kin=None)\n",
      "potential info\n",
      " tensor([6.8869e-11, 6.8869e-11, 6.8869e-11,  ..., 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "derivative of potential info wrt density\n",
      " ValGrad(value=tensor([8.0012e-07, 8.0012e-07, 8.0012e-07,  ..., 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00], dtype=torch.float64, grad_fn=<AddBackward0>), grad=None, lapl=None, kin=None)\n",
      "torch.Size([18, 18, 18, 18])\n"
     ]
    }
   ],
   "source": [
    "dvxc_wrt_dro = get_dvxc_wrt_dro_dm(qc._engine.hamilton, dm)\n",
    "print(dvxc_wrt_dro.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1e83ed",
   "metadata": {},
   "source": [
    "It is, I guess, tensor of Couloumb term: \n",
    "$$\\iint b_i(\\vec{r}) \\frac{b_k(\\vec{r'})b_l(\\vec{r'})}{|\\vec{r}-\\vec{r'}|} b_j(\\vec{r})d\\vec{r'}d\\vec{r}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "755eecf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 18, 18, 18])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electronic_repulsion_tensor = qc._engine.hamilton.el_mat\n",
    "electronic_repulsion_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a5349",
   "metadata": {},
   "source": [
    "It must have symmetry of i<->j and k<->l permutations, let's check it. We are going to calculate something like norm of remainder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81412822",
   "metadata": {},
   "source": [
    "i<->j, OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4ee1b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.9071e-13, dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij->\", torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4adb8",
   "metadata": {},
   "source": [
    "i<->k, not OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1558ceca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(216.4966, dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij->\", torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(0, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d38a836",
   "metadata": {},
   "source": [
    "i<->l, not OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1bbe8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(216.4966, dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij->\", torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(0, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50d29a",
   "metadata": {},
   "source": [
    "j<->k, not OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc214bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(216.4966, dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij->\", torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3477cf",
   "metadata": {},
   "source": [
    "j<->l, not OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6347484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(216.4966, dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij->\", torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(1, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7061c6",
   "metadata": {},
   "source": [
    "k<->l, OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58c09194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8773e-14, dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij->\", torch.linalg.matrix_norm(electronic_repulsion_tensor - electronic_repulsion_tensor.transpose(2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4599e26",
   "metadata": {},
   "source": [
    "Let's sum our two tensors (NB: now it loses symmetry of XC-tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "613b9f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 18, 18, 18])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourDtensor = dvxc_wrt_dro + electronic_repulsion_tensor\n",
    "fourDtensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cf4c2b",
   "metadata": {},
   "source": [
    "Let's calculate the second term:\n",
    "$$\\frac{\\partial r_{ia}(\\textbf{C};\\;\\vec{\\theta})}{\\partial C_{ck}} = (F_{ik}[\\rho](\\vec{\\theta}) - \\epsilon_c\\delta_{ik})\\delta_{ac} + 2f_c\\sum_j \\sum_{l}C_{cl}\\left(G_{Cou,ijkl} + G_{XC,ijkl}\\right)C_{aj}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "542378d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import xitorch as xt\n",
    "from dqc.utils.datastruct import SpinParam\n",
    "\n",
    "def _symm(scp: torch.Tensor):\n",
    "    # forcely symmetrize the tensor\n",
    "    return (scp + scp.transpose(-2, -1)) * 0.5\n",
    "\n",
    "def scp2orbital_energies(hf_engine, scp: torch.Tensor) -> Union[torch.Tensor, SpinParam[torch.Tensor]]:\n",
    "    # scp is like KS, using the concatenated Fock matrix\n",
    "    if not hf_engine._polarized:\n",
    "        fock = xt.LinearOperator.m(_symm(scp), is_hermitian=True)\n",
    "        return fock2orbital_energies(hf_engine, fock)\n",
    "    else:\n",
    "        fock_u = xt.LinearOperator.m(_symm(scp[0]), is_hermitian=True)\n",
    "        fock_d = xt.LinearOperator.m(_symm(scp[1]), is_hermitian=True)\n",
    "        return fock2orbital_energies(hf_engine, SpinParam(u=fock_u, d=fock_d))\n",
    "\n",
    "def fock2orbital_energies(hf_engine, fock):\n",
    "    # diagonalize the fock matrix and obtain the density matrix\n",
    "    eigvals, _ = hf_engine.diagonalize(fock, hf_engine._norb)\n",
    "    return eigvals\n",
    "\n",
    "def scp2orbital_decomposition(hf_engine, scp: torch.Tensor) -> Union[torch.Tensor, SpinParam[torch.Tensor]]:\n",
    "    # scp is like KS, using the concatenated Fock matrix\n",
    "    if not hf_engine._polarized:\n",
    "        fock = xt.LinearOperator.m(_symm(scp), is_hermitian=True)\n",
    "        return fock2orbital_decomposition(hf_engine, fock)\n",
    "    else:\n",
    "        fock_u = xt.LinearOperator.m(_symm(scp[0]), is_hermitian=True)\n",
    "        fock_d = xt.LinearOperator.m(_symm(scp[1]), is_hermitian=True)\n",
    "        return fock2orbital_decomposition(hf_engine, SpinParam(u=fock_u, d=fock_d))\n",
    "\n",
    "def fock2orbital_decomposition(hf_engine, fock):\n",
    "    _, eigvectors = hf_engine.diagonalize(fock, hf_engine._norb)\n",
    "    return eigvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4601033",
   "metadata": {},
   "outputs": [],
   "source": [
    "fock = qc._engine.dm2scp(dm).clone()\n",
    "coeff = scp2orbital_decomposition(qc._engine.hf_engine, fock)\n",
    "orbital_energies = scp2orbital_energies(qc._engine.hf_engine, fock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e11b467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 7])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9e3afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_wrt_dC = torch.einsum(\"ijkl,lc,ja->iack\", fourDtensor, coeff, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81652a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 7, 7, 18])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_wrt_dC.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
